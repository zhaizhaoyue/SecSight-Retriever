
# Model Configuration
models:
  llm:
    provider: "DeepSeek"
    model_name: "deepseek-chat"
    max_tokens: 4096
    temperature: 0.1
    
  embedding:
    model_name: "sentence-transformers/all-MiniLM-L6-v2"
    device: "cuda"

# Dataset Configuration
dataset:
  fine:
    data_path: "data/fine/"
    train_split: 0.8
    val_split: 0.1
    test_split: 0.1

# AIE Framework Module Configuration
aie_framework:
  segmentation:
    max_segment_length: 1000
    overlap_ratio: 0.1
    split_method: "semantic"
    
  retrieval:
    top_k: 5  # Number of top segments to retrieve
    similarity_threshold: 0.5  # Similarity threshold
    retrieval_method: "dense"  # Options: dense, sparse, hybrid
    
  summarization:
    strategy: "refine"  # Options: refine, map_reduce, stuff
    max_summary_length: 500  # Maximum summary length
    chunk_size: 2000  # Chunk size for Refine strategy
    
  extraction:
    prompt_template: "templates/extraction_prompt.txt"
    output_format: "json"  # Options: json, structured
    max_retries: 3  # Maximum retries when extraction fails

# Evaluation Configuration
evaluation:
  metrics:
    - "exact_match"
    - "f1_score"
    - "precision"
    - "recall"
    - "rouge"
  
  output_dir: "results/"
  save_predictions: true
  save_intermediate_results: true

# Experiment Configuration
experiments:
  batch_size: 8
  num_workers: 4
  seed: 42
  log_level: "INFO"
  save_checkpoints: true
  
# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/aie_framework.log"
