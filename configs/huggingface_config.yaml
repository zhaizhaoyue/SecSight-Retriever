
# AIE Framework Configuration File (HuggingFace Local Models)

# Model Configuration
models:
  llm:
    provider: "DeepSeek"
    model_name: "deepseek-chat"
    api_key: "sk-b4f98bd0609246c2ba28f0eb0ad549ea"
    max_tokens: 4096
    temperature: 0.1
    
  embedding:
    model_name: "sentence-transformers/all-MiniLM-L6-v2"
    device: "cuda"

# Dataset Configuration
dataset:
  fine:
    data_path: "data/fine/"
    train_split: 0.8
    val_split: 0.1
    test_split: 0.1

# AIE Framework Module Configuration (optimized for local models)
aie_framework:
  segmentation:
    max_segment_length: 500  # Smaller segments for local models
    overlap_ratio: 0.1
    split_method: "fixed"  # Faster method
    
  retrieval:
    top_k: 3  # Fewer segments to reduce processing
    similarity_threshold: 0.3
    retrieval_method: "dense"
    
  summarization:
    strategy: "stuff"  # Simpler strategy for local models
    max_summary_length: 300
    chunk_size: 1000
    
  extraction:
    prompt_template: "templates/extraction_prompt.txt"
    output_format: "json"
    max_retries: 2

# Evaluation Configuration
evaluation:
  metrics:
    - "exact_match"
    - "f1_score"
    - "precision"
    - "recall"
  
  output_dir: "results/"
  save_predictions: true
  save_intermediate_results: true

# Experiment Configuration
experiments:
  batch_size: 2  # Smaller batch for local processing
  num_workers: 2
  seed: 42
  log_level: "INFO"
  save_checkpoints: true
  
# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/aie_framework.log"
