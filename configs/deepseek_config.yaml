# AIE Framework Configuration File (DeepSeek)

# Model Configuration
models:
  llm:
    provider: "DeepSeek"
    model_name: "deepseek-chat"
    api_key: "sk-b4f98bd0609246c2ba28f0eb0ad549ea"
    max_tokens: 4096
    temperature: 0.1
    
  embedding:
    model_name: "sentence-transformers/all-mpnet-base-v2"
    device: "cuda"  # Or "cuda" if GPU available

# Dataset Configuration
dataset:
  fine:
    data_path: "data/fine/"
    train_split: 0.8
    val_split: 0.1
    test_split: 0.1

# AIE Framework Module Configuration
aie_framework:
  segmentation:
    max_segment_length: 1000  # Maximum segment length (character count)
    overlap_ratio: 0.1  # Segment overlap ratio
    split_method: "semantic"  # Options: semantic, fixed, adaptive
    
  retrieval:
    top_k: 5  # Number of top segments to retrieve
    similarity_threshold: 0.01  # Similarity threshold (lowered for BM25)
    retrieval_method: "sparse"  # Options: dense, sparse, hybrid
    algorithm: "bm25"  # For sparse: bm25 or tfidf
    k1: 1.2  # BM25 parameter
    b: 0.75  # BM25 parameter
    
  summarization:
    strategy: "refine"  # Options: refine, map_reduce, stuff
    max_summary_length: 500  # Maximum summary length
    chunk_size: 2000  # Chunk size for Refine strategy
    
  extraction:
    prompt_template: "templates/extraction_prompt.txt"
    output_format: "json"  # Options: json, structured
    max_retries: 3  # Maximum retries when extraction fails

# Evaluation Configuration
evaluation:
  metrics:
    - "exact_match"
    - "f1_score"
    - "precision"
    - "recall"
    - "rouge"
  
  output_dir: "results/"
  save_predictions: true
  save_intermediate_results: true

# Experiment Configuration
experiments:
  batch_size: 8
  num_workers: 4
  seed: 42
  log_level: "INFO"
  save_checkpoints: true
  
# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/aie_framework.log"
